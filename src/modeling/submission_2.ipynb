{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission 1\n",
    "\n",
    "- Baseline\n",
    "    - Missing data is filled with outlier values like 'missing', 99 etc\n",
    "    - Label Encoding of all the categorical variables\n",
    "    - LGBM\n",
    "- Redefined the orders of ord_1, ord_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Shape of train.csv : (600000, 24)\n",
      "Shape of test.csv : (400000, 23)\n",
      "Shape of sample_submission.csv : (400000, 2)\n",
      "Data Loaded...\n",
      "Shape of the combined DF (1000000, 23)\n",
      "Number of nominal features 10\n",
      "Nominal Features : ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\n",
      "Number of binary features 5\n",
      "Binary Features : ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\n",
      "Number of ordinal features 6\n",
      "Ordinal Features : ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']\n",
      "Converting ord_0 in ordered categorical\n",
      "Converting ord_3 in ordered categorical\n",
      "Converting ord_4 in ordered categorical\n",
      "Converting ord_5 in ordered categorical\n",
      "Categories for feature ord_1_cat : Index(['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster',\n",
      "       'missing_ord'],\n",
      "      dtype='object')\n",
      "Categories for feature ord_2_cat : Index(['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot',\n",
      "       'missing_ord'],\n",
      "      dtype='object')\n",
      "Categories for feature ord_0_cat : Float64Index([1.0, 2.0, 3.0, 999.0], dtype='float64')\n",
      "Categories for feature ord_3_cat : Index(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
      "       'missing_ord', 'n', 'o'],\n",
      "      dtype='object')\n",
      "Categories for feature ord_4_cat : Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
      "       'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
      "       'missing_ord'],\n",
      "      dtype='object')\n",
      "Categories for feature ord_5_cat : Index(['AG', 'AI', 'AU', 'AW', 'Ay', 'BL', 'BX', 'Bx', 'CN', 'CU',\n",
      "       ...\n",
      "       'wa', 'xB', 'xF', 'xG', 'yE', 'yK', 'zc', 'ze', 'zf', 'zp'],\n",
      "      dtype='object', length=191)\n",
      "List of new_features ['ord_1_cat', 'ord_2_cat', 'ord_0_cat', 'ord_3_cat', 'ord_4_cat', 'ord_5_cat']\n",
      "List of new_features ['ord_1', 'ord_2', 'ord_0', 'ord_3', 'ord_4', 'ord_5']\n",
      "Converting bin_0 in categorical\n",
      "Converting bin_1 in categorical\n",
      "Converting bin_2 in categorical\n",
      "Converting bin_3 in categorical\n",
      "Converting bin_4 in categorical\n",
      "Converting nom_0 in categorical\n",
      "Converting nom_1 in categorical\n",
      "Converting nom_2 in categorical\n",
      "Converting nom_3 in categorical\n",
      "Converting nom_4 in categorical\n",
      "Converting nom_5 in categorical\n",
      "Converting nom_6 in categorical\n",
      "Converting nom_7 in categorical\n",
      "Converting nom_8 in categorical\n",
      "Converting nom_9 in categorical\n",
      "Converting day in categorical\n",
      "Converting month in categorical\n",
      "ord_1_cat\n",
      "ord_2_cat\n",
      "ord_0_cat\n",
      "ord_3_cat\n",
      "ord_4_cat\n",
      "ord_5_cat\n",
      "bin_0_cat\n",
      "bin_1_cat\n",
      "bin_2_cat\n",
      "bin_3_cat\n",
      "bin_4_cat\n",
      "nom_0_cat\n",
      "nom_1_cat\n",
      "nom_2_cat\n",
      "nom_3_cat\n",
      "nom_4_cat\n",
      "nom_5_cat\n",
      "nom_6_cat\n",
      "nom_7_cat\n",
      "nom_8_cat\n",
      "nom_9_cat\n",
      "day_cat\n",
      "month_cat\n",
      "(600000, 23)\n",
      "(400000, 23)\n",
      "(600000,)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sys.path.insert(0, \"/home/jupyter/kaggle/cat_in_dat_2/kaggle_cat_in_dat_2/src\")\n",
    "import utility\n",
    "\n",
    "DATA_DIR = '/home/jupyter/kaggle/cat_in_dat_2/kaggle_cat_in_dat_2/data/read_only'\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "utility.set_seed(SEED)\n",
    "\n",
    "#Read the data file\n",
    "train, test, submission = utility.read_files(DATA_DIR, index_col='id')\n",
    "\n",
    "combined_df = pd.concat([train.drop('target', axis=1), test])\n",
    "print(f'Shape of the combined DF {combined_df.shape}')\n",
    "\n",
    "train_index = train.shape[0]\n",
    "train_Y = train.target\n",
    "\n",
    "# Fill the missing values\n",
    "nom_features = utility.get_fetaure_names(train, 'nom')\n",
    "print(f'Number of nominal features {len(nom_features)}')\n",
    "print(f'Nominal Features : {nom_features}')\n",
    "\n",
    "binary_features = utility.get_fetaure_names(train, 'bin')\n",
    "print(f'Number of binary features {len(binary_features)}')\n",
    "print(f'Binary Features : {binary_features}')\n",
    "\n",
    "ordinal_fetaures = utility.get_fetaure_names(train, 'ord')\n",
    "print(f'Number of ordinal features {len(ordinal_fetaures)}')\n",
    "print(f'Ordinal Features : {ordinal_fetaures}')\n",
    "\n",
    "#Filling missing values\n",
    "combined_df[['bin_3', 'bin_4']] = combined_df[['bin_3', 'bin_4']].fillna('missing_binary')\n",
    "combined_df[['bin_0', 'bin_1', 'bin_2']] = combined_df[['bin_0', 'bin_1', 'bin_2']].fillna(-1)\n",
    "\n",
    "# Filling nominal variables with missing values\n",
    "combined_df[nom_features] = combined_df[nom_features].fillna('missing_nom')\n",
    "\n",
    "# ord_0 has apparently value fo type integer. \n",
    "combined_df['ord_0'] = combined_df['ord_0'].fillna(999)\n",
    "\n",
    "# Fill missing values for other ordinal values\n",
    "combined_df[['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']] = combined_df[['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']].fillna('missing_ord')\n",
    "\n",
    "combined_df['day'] = combined_df['day'].fillna(999) \n",
    "combined_df['month'] = combined_df['month'].fillna(999)\n",
    "\n",
    "# List to maintain names\n",
    "new_features = []\n",
    "features_to_removed = []\n",
    "\n",
    "# For  ord_1, ord_2 we can decide on the order based on names\n",
    "cat_type_ord_1 = pd.CategoricalDtype(categories=['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster', 'missing_ord'])\n",
    "combined_df['ord_1_cat'] = combined_df['ord_1'].astype(cat_type_ord_1)\n",
    "\n",
    "cat_type_ord_2 = pd.CategoricalDtype(categories=['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot', 'missing_ord'])\n",
    "combined_df['ord_2_cat'] = combined_df['ord_2'].astype(cat_type_ord_2)\n",
    "\n",
    "new_features = new_features + ['ord_1_cat', 'ord_2_cat']\n",
    "features_to_removed = features_to_removed + ['ord_1', 'ord_2']\n",
    "\n",
    "# Convert rest of the ordinal features in categories \n",
    "for feature_name in ['ord_0', 'ord_3', 'ord_4', 'ord_5']:\n",
    "    print(f'Converting {feature_name} in ordered categorical')\n",
    "    combined_df[feature_name + '_cat'] = pd.Categorical(combined_df[feature_name], ordered=True)\n",
    "    new_features = new_features + [feature_name + '_cat']\n",
    "    features_to_removed = features_to_removed + [feature_name]\n",
    "\n",
    "# Print the order of the ordinal features\n",
    "for name in utility.get_fetaure_names(combined_df, '_cat'):\n",
    "    print(f'Categories for feature {name} : {combined_df[name].cat.categories}')\n",
    "\n",
    "print(f'List of new_features : {new_features}')\n",
    "print(f'List of features_to_removed : {features_to_removed}')\n",
    "\n",
    "feature_list = [name for name in combined_df.select_dtypes(['object', 'float64']) if name not in features_to_removed]\n",
    "# Print rest of the variables into categorical\n",
    "for feature_name in feature_list:\n",
    "    print(f'Converting {feature_name} in categorical')\n",
    "    combined_df[feature_name + '_cat'] = pd.Categorical(combined_df[feature_name])\n",
    "    new_features = new_features + [feature_name + '_cat']\n",
    "    features_to_removed = features_to_removed + [feature_name]\n",
    "\n",
    "# Keep a copy of the original DF\n",
    "combined_df_org = combined_df.copy(deep=True)\n",
    "\n",
    "# remove the features not needed\n",
    "combined_df = combined_df.drop(features_to_removed, axis=1)\n",
    "\n",
    "for name in combined_df.columns:\n",
    "    lb = LabelEncoder()\n",
    "    print(name)\n",
    "    combined_df[name] = lb.fit_transform(combined_df[name])\n",
    "\n",
    "train_X = combined_df[:train_index]\n",
    "test_X = combined_df[train_index:]\n",
    "\n",
    "print(f\"train_X : {train_X.shape}\")\n",
    "print(f\"test_X : {test_X.shape}\")\n",
    "print(f\"train_Y : {train_Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM + Strartified 5 folds + 10000 trees + 100 early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning:\n",
      "\n",
      "Found `num_trees` in params. Will use it instead of argument\n",
      "\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning:\n",
      "\n",
      "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.753004\tvalid_1's auc: 0.747302\n",
      "[100]\ttraining's auc: 0.766619\tvalid_1's auc: 0.758266\n",
      "[150]\ttraining's auc: 0.77555\tvalid_1's auc: 0.764179\n",
      "[200]\ttraining's auc: 0.782059\tvalid_1's auc: 0.767375\n",
      "[250]\ttraining's auc: 0.786991\tvalid_1's auc: 0.768664\n",
      "[300]\ttraining's auc: 0.791405\tvalid_1's auc: 0.769468\n",
      "[350]\ttraining's auc: 0.795684\tvalid_1's auc: 0.770301\n",
      "[400]\ttraining's auc: 0.799561\tvalid_1's auc: 0.770516\n",
      "[450]\ttraining's auc: 0.803401\tvalid_1's auc: 0.770871\n",
      "[500]\ttraining's auc: 0.807047\tvalid_1's auc: 0.770798\n",
      "Early stopping, best iteration is:\n",
      "[442]\ttraining's auc: 0.802829\tvalid_1's auc: 0.770956\n",
      "CV OOF Score for fold 1 is 0.7709556880146894\n",
      "fold 2 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning:\n",
      "\n",
      "Found `num_trees` in params. Will use it instead of argument\n",
      "\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning:\n",
      "\n",
      "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.753019\tvalid_1's auc: 0.747319\n",
      "[100]\ttraining's auc: 0.76679\tvalid_1's auc: 0.758293\n",
      "[150]\ttraining's auc: 0.775758\tvalid_1's auc: 0.764581\n",
      "[200]\ttraining's auc: 0.781985\tvalid_1's auc: 0.767374\n",
      "[250]\ttraining's auc: 0.787119\tvalid_1's auc: 0.769014\n",
      "[300]\ttraining's auc: 0.791637\tvalid_1's auc: 0.770131\n",
      "[350]\ttraining's auc: 0.795777\tvalid_1's auc: 0.770702\n",
      "[400]\ttraining's auc: 0.799699\tvalid_1's auc: 0.771008\n",
      "[450]\ttraining's auc: 0.803523\tvalid_1's auc: 0.77137\n",
      "[500]\ttraining's auc: 0.807085\tvalid_1's auc: 0.771392\n",
      "[550]\ttraining's auc: 0.810539\tvalid_1's auc: 0.771702\n",
      "[600]\ttraining's auc: 0.813892\tvalid_1's auc: 0.771739\n",
      "[650]\ttraining's auc: 0.817202\tvalid_1's auc: 0.77191\n",
      "[700]\ttraining's auc: 0.820373\tvalid_1's auc: 0.771708\n",
      "[750]\ttraining's auc: 0.823472\tvalid_1's auc: 0.7716\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttraining's auc: 0.817806\tvalid_1's auc: 0.771914\n",
      "CV OOF Score for fold 2 is 0.771914127465997\n",
      "fold 3 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning:\n",
      "\n",
      "Found `num_trees` in params. Will use it instead of argument\n",
      "\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning:\n",
      "\n",
      "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.753987\tvalid_1's auc: 0.742968\n",
      "[100]\ttraining's auc: 0.768188\tvalid_1's auc: 0.754752\n",
      "[150]\ttraining's auc: 0.776234\tvalid_1's auc: 0.759957\n",
      "[200]\ttraining's auc: 0.782656\tvalid_1's auc: 0.763391\n",
      "[250]\ttraining's auc: 0.78788\tvalid_1's auc: 0.76532\n",
      "[300]\ttraining's auc: 0.792245\tvalid_1's auc: 0.766316\n",
      "[350]\ttraining's auc: 0.796463\tvalid_1's auc: 0.767047\n",
      "[400]\ttraining's auc: 0.800371\tvalid_1's auc: 0.767631\n",
      "[450]\ttraining's auc: 0.804018\tvalid_1's auc: 0.76778\n",
      "[500]\ttraining's auc: 0.807506\tvalid_1's auc: 0.767805\n",
      "[550]\ttraining's auc: 0.810972\tvalid_1's auc: 0.767974\n",
      "[600]\ttraining's auc: 0.81438\tvalid_1's auc: 0.768046\n",
      "[650]\ttraining's auc: 0.817621\tvalid_1's auc: 0.767917\n",
      "Early stopping, best iteration is:\n",
      "[582]\ttraining's auc: 0.813151\tvalid_1's auc: 0.768093\n",
      "CV OOF Score for fold 3 is 0.7680927742203882\n",
      "fold 4 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning:\n",
      "\n",
      "Found `num_trees` in params. Will use it instead of argument\n",
      "\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning:\n",
      "\n",
      "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.752762\tvalid_1's auc: 0.748203\n",
      "[100]\ttraining's auc: 0.766529\tvalid_1's auc: 0.759309\n",
      "[150]\ttraining's auc: 0.774808\tvalid_1's auc: 0.764436\n",
      "[200]\ttraining's auc: 0.781231\tvalid_1's auc: 0.767633\n",
      "[250]\ttraining's auc: 0.786324\tvalid_1's auc: 0.769275\n",
      "[300]\ttraining's auc: 0.791118\tvalid_1's auc: 0.770584\n",
      "[350]\ttraining's auc: 0.795053\tvalid_1's auc: 0.770992\n",
      "[400]\ttraining's auc: 0.79885\tvalid_1's auc: 0.771279\n",
      "[450]\ttraining's auc: 0.802546\tvalid_1's auc: 0.771615\n",
      "[500]\ttraining's auc: 0.806335\tvalid_1's auc: 0.772228\n",
      "[550]\ttraining's auc: 0.80994\tvalid_1's auc: 0.772234\n",
      "[600]\ttraining's auc: 0.813358\tvalid_1's auc: 0.772357\n",
      "[650]\ttraining's auc: 0.816685\tvalid_1's auc: 0.772367\n",
      "[700]\ttraining's auc: 0.819923\tvalid_1's auc: 0.772605\n",
      "[750]\ttraining's auc: 0.822866\tvalid_1's auc: 0.772564\n",
      "[800]\ttraining's auc: 0.825966\tvalid_1's auc: 0.772775\n",
      "[850]\ttraining's auc: 0.828964\tvalid_1's auc: 0.772853\n",
      "[900]\ttraining's auc: 0.831776\tvalid_1's auc: 0.77288\n",
      "[950]\ttraining's auc: 0.834587\tvalid_1's auc: 0.772755\n",
      "Early stopping, best iteration is:\n",
      "[890]\ttraining's auc: 0.831242\tvalid_1's auc: 0.772927\n",
      "CV OOF Score for fold 4 is 0.772926986031897\n",
      "fold 5 of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning:\n",
      "\n",
      "Found `num_trees` in params. Will use it instead of argument\n",
      "\n",
      "/home/jupyter/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning:\n",
      "\n",
      "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.752427\tvalid_1's auc: 0.750744\n",
      "[100]\ttraining's auc: 0.766478\tvalid_1's auc: 0.762664\n",
      "[150]\ttraining's auc: 0.774765\tvalid_1's auc: 0.768034\n",
      "[200]\ttraining's auc: 0.781304\tvalid_1's auc: 0.771163\n",
      "[250]\ttraining's auc: 0.786344\tvalid_1's auc: 0.772673\n",
      "[300]\ttraining's auc: 0.790717\tvalid_1's auc: 0.773483\n",
      "[350]\ttraining's auc: 0.795029\tvalid_1's auc: 0.774255\n",
      "[400]\ttraining's auc: 0.798722\tvalid_1's auc: 0.774279\n",
      "[450]\ttraining's auc: 0.802342\tvalid_1's auc: 0.774592\n",
      "[500]\ttraining's auc: 0.806206\tvalid_1's auc: 0.774822\n",
      "[550]\ttraining's auc: 0.809512\tvalid_1's auc: 0.775002\n",
      "[600]\ttraining's auc: 0.812769\tvalid_1's auc: 0.775014\n",
      "Early stopping, best iteration is:\n",
      "[540]\ttraining's auc: 0.80895\tvalid_1's auc: 0.775052\n",
      "CV OOF Score for fold 5 is 0.7750523786515673\n",
      "Combined OOF score : 0.77177\n",
      "Average of 5 folds OOF score 0.77179\n",
      "std of 5 folds OOF score 0.00229\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'boosting_type':'gbdt',\n",
    "    'metric':'auc',\n",
    "    'n_jobs':-1,\n",
    "    'verbose':-1,\n",
    "    'seed': SEED,\n",
    "    'num_trees':10000,\n",
    "    'early_stopping_rounds':100,\n",
    "    }\n",
    "\n",
    "result_dict = utility.make_prediction(train_X, train_Y, test_X, params=lgb_params, n_splits=5, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM + Strartified 5 folds + Defualt parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 of 5\n",
      "[50]\ttraining's auc: 0.753004\tvalid_1's auc: 0.747302\n",
      "[100]\ttraining's auc: 0.766619\tvalid_1's auc: 0.758266\n",
      "CV OOF Score for fold 1 is 0.7582659115440875\n",
      "fold 2 of 5\n",
      "[50]\ttraining's auc: 0.753019\tvalid_1's auc: 0.747319\n",
      "[100]\ttraining's auc: 0.76679\tvalid_1's auc: 0.758293\n",
      "CV OOF Score for fold 2 is 0.7582928189220268\n",
      "fold 3 of 5\n",
      "[50]\ttraining's auc: 0.753987\tvalid_1's auc: 0.742968\n",
      "[100]\ttraining's auc: 0.768188\tvalid_1's auc: 0.754752\n",
      "CV OOF Score for fold 3 is 0.7547516721185684\n",
      "fold 4 of 5\n",
      "[50]\ttraining's auc: 0.752762\tvalid_1's auc: 0.748203\n",
      "[100]\ttraining's auc: 0.766529\tvalid_1's auc: 0.759309\n",
      "CV OOF Score for fold 4 is 0.7593093024755377\n",
      "fold 5 of 5\n",
      "[50]\ttraining's auc: 0.752427\tvalid_1's auc: 0.750744\n",
      "[100]\ttraining's auc: 0.766478\tvalid_1's auc: 0.762664\n",
      "CV OOF Score for fold 5 is 0.7626639300312533\n",
      "Combined OOF score : 0.75865\n",
      "Average of 5 folds OOF score 0.75866\n",
      "std of 5 folds OOF score 0.00253\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'boosting_type':'gbdt',\n",
    "    'metric':'auc',\n",
    "    'n_jobs':-1,\n",
    "    'verbose':-1,\n",
    "    'seed': SEED\n",
    "    }\n",
    "\n",
    "result_dict = utility.make_prediction(train_X, train_Y, test_X, params=lgb_params, n_splits=5, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.target = result_dict['prediction']\n",
    "submission.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! kaggle competitions submit -c cat-in-the-dat -f submission_1.csv -m \"Baseline solutions\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_37",
   "language": "python",
   "name": "py_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
